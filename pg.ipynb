{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test llama with new retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/anaconda3/envs/code-chunker/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import np\n",
    "import pickle\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from sentence_transformers.cross_encoder import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = dict({\"OPENAI\":'gpt-4o'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OPENAI'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "class code(BaseModel):\n",
    "    \"\"\"\n",
    "    Schema for code solutions for questions about tskit. \n",
    "    \"\"\"\n",
    "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
    "    imports: str = Field(description=\"Code block import statements\")\n",
    "    code: str = Field(description=\"Code block should contain function that can be called. It should have input file_path to tree_sequence. It should not include import statements\")\n",
    "\n",
    "def rerank_documents(query: str,reranker, documents: list, top_k: int = 3) -> list:\n",
    "    \"\"\"Re-rank documents using cross-encoder\"\"\"\n",
    "    pairs = [(query, doc.page_content) for doc in documents]\n",
    "    \n",
    "    scores = reranker.predict(pairs)\n",
    "    \n",
    "    ranked_indices = np.argsort(scores)[::-1]  \n",
    "    ranked_docs = [documents[i] for i in ranked_indices]\n",
    "    \n",
    "    return ranked_docs[:top_k]\n",
    "\n",
    "import re\n",
    "def response_parser(text):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'prefix': '',\n",
    "        'imports': '',\n",
    "        'code': ''\n",
    "    }\n",
    "    sections = re.split(r'\\*\\*([^\\*]+)\\*\\*', text)\n",
    "\n",
    "    for i in range(1, len(sections), 2):\n",
    "        header = sections[i].strip()\n",
    "        content = sections[i+1].strip()\n",
    "        if header == 'Prefix':\n",
    "            result['prefix'] = content\n",
    "        \n",
    "        elif header == 'Imports':\n",
    "            code_match = re.search(r'```python(.*?)```', content, re.DOTALL)\n",
    "            if code_match:\n",
    "                result['imports'] = code_match.group(1).strip()\n",
    "\n",
    "        elif header == 'Code':\n",
    "            code_match = re.search(r'```python(.*?)```', content, re.DOTALL)\n",
    "            if code_match:\n",
    "                result['code'] = code_match.group(1).strip()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def generatorTool(question, context, input_file_path=None, model_nama='llama3.2', ollama_client='https://uwx72r685xxxb8-11434.proxy.runpod.net/'):\n",
    "    try:\n",
    "\n",
    "            # Set up template\n",
    "        template = \"\"\"You are a Python coding generator with expertise in using tskit toolkit for analysing tree-sequences. \\n \n",
    "        Here is a relevant set of tskit documentation:  \\n ------- \\n  {context} \\n ------- \\n Use the tskit module to answer the user \n",
    "        question based on the above provided documentation. Ensure any code you provide should be a callable function and can be executed \\n \n",
    "        with all required imports and variables defined. Structure your answer with a description of the code solution. \\n\n",
    "        Do not give example usage, simply create a function that is callable with a tree file as an input. \\n\n",
    "        Then list the imports. And finally list the functioning code block. The function should return a string providing the answer. Maintain this order which is: \\n\n",
    "        1. Prefix (code description and helpful information about the tree sequence)\\n\n",
    "        2. Imports (required code imports like tskit, to run the code in Python, write them as import statements)\\n\n",
    "        3. Code (code block which is a callable function with a tree sequence file as an input parameter, does not include import statements)\\n\n",
    "        if the question is irrelevant to code-generation. respond appropriately\n",
    "        Here is the user question: {question}\"\"\"\n",
    "    \n",
    "        # lm = ChatOllama(model=MODEL_NAME, temperature=0)\n",
    "        \n",
    "        # structured_code_llm = lm.with_structured_output(code, include_raw=True)\n",
    "\n",
    "\n",
    "        code_gen_prompt = ChatPromptTemplate.from_template(template)\n",
    "        filled_prompt = code_gen_prompt.format(context=context, question=question)\n",
    "\n",
    "        client = ollama.Client(host=ollama_client)\n",
    "\n",
    "        response = client.chat(\n",
    "            messages=[\n",
    "                {\n",
    "                    'role': 'user',\n",
    "                    'content': filled_prompt,\n",
    "                }\n",
    "            ],\n",
    "            model=model_nama,\n",
    "            # format=code.model_json_schema(),\n",
    "            options={'temperature': 0}\n",
    "            )\n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Tools Error:\", e)\n",
    "        return f\"Found Error while processing your query\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## retriever setup\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vector_store = FAISS.load_local(folder_path=\"./code-chunker/faiss-vector\", embeddings=embeddings, index_name=\"faiss_index\", allow_dangerous_deserialization=True)\n",
    "\n",
    "## Load documents for BM25Retriever\n",
    "with open(\"./code-chunker/documents.pkl\", 'rb') as file:\n",
    "    all_documents = pickle.load(file)\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(documents=all_documents, k=10, search_kwargs={\"k\": 10})\n",
    "\n",
    "faiss_retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.5, \"k\": 10}\n",
    ")\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever],\n",
    "    weights=[0.5, 0.5]  # Adjust based on your use case\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many sites have 1 mutations [Document(metadata={'title': 'num_mutations'}, page_content='    @property\\n    def num_mutations(self):\\n        \"\"\"\\n        Returns the total number of mutations across all sites on this tree.\\n\\n        :return: The total number of mutations over all sites on this tree.\\n        :rtype: int\\n        \"\"\"\\n        return sum(len(site.mutations) for site in self.sites())\\n'), Document(id='2e299a15-9360-424b-84de-c154ebef7ed6', metadata={'title': 'mutations_site'}, page_content='    @property\\n    def mutations_site(self):\\n        \"\"\"\\n        Efficient access to the ``site`` column in the\\n        :ref:`sec_mutation_table_definition` as a numpy array (dtype=np.int32).\\n        Equivalent to ``ts.tables.mutations.site`` (but avoiding the full copy\\n        of the table data that accessing ``ts.tables`` currently entails).\\n        \"\"\"\\n        return self._mutations_site\\n'), Document(metadata={'title': 'Tajimas_D'}, page_content='    def Tajimas_D(self, sample_sets=None, windows=None, mode=\"site\"):\\n        \"\"\"\\n        Computes Tajima\\'s D of sets of nodes from ``sample_sets`` in windows.\\n        Please see the :ref:`one-way statistics <sec_stats_sample_sets_one_way>`\\n        section for details on how the ``sample_sets`` argument is interpreted\\n        and how it interacts with the dimensions of the output array.\\n        See the :ref:`statistics interface <sec_stats_interface>` section for details on\\n        :ref:`windows <sec_stats_windows>`, :ref:`mode <sec_stats_mode>`,\\n        and :ref:`return value <sec_stats_output_format>`.\\n        Operates on ``k = 1`` sample sets at a\\n        time. For a sample set ``X`` of ``n`` nodes, if and ``T`` is the mean\\n        number of pairwise differing sites in ``X`` and ``S`` is the number of\\n        sites segregating in ``X`` (computed with :meth:`diversity\\n        <.TreeSequence.diversity>` and :meth:`segregating sites\\n        <.TreeSequence.segregating_sites>`, respectively, both not span\\n        normalised), then Tajima\\'s D is\\n\\n        .. code-block:: python\\n\\n            D = (T - S / h) / sqrt(a * S + (b / c) * S * (S - 1))\\n            h = 1 + 1 / 2 + ... + 1 / (n - 1)\\n            g = 1 + 1 / 2**2 + ... + 1 / (n - 1) ** 2\\n            a = (n + 1) / (3 * (n - 1) * h) - 1 / h**2\\n            b = 2 * (n**2 + n + 3) / (9 * n * (n - 1)) - (n + 2) / (h * n) + g / h**2\\n            c = h**2 + g\\n\\n        What is computed for diversity and divergence depends on ``mode``;\\n        see those functions for more details.\\n\\n        :param list sample_sets: A list of lists of Node IDs, specifying the\\n            groups of nodes to compute the statistic with.\\n        :param list indexes: A list of 2-tuples, or None.\\n        :param list windows: An increasing list of breakpoints between the windows\\n            to compute the statistic in.\\n        :param str mode: A string giving the \"type\" of the statistic to be computed\\n            (defaults to \"site\").\\n        :return: A ndarray with shape equal to (num windows, num statistics).\\n            If there is one sample set and windows=None, a numpy scalar is returned.\\n        \"\"\"\\n'), Document(id='2eda8908-70be-4353-b91a-5a97be5d2699', metadata={'title': 'mutations'}, page_content='    def mutations(self):\\n        \"\"\"\\n        Returns an iterator over all the\\n        :ref:`mutations <sec_mutation_table_definition>` in this tree sequence.\\n        Mutations are returned in order of nondecreasing site ID.\\n        See the :class:`Mutation` class for details on the available fields for\\n        each mutation.\\n\\n        The returned iterator is equivalent to iterating over all sites\\n        and all mutations in each site, i.e.::\\n\\n            >>> for site in tree_sequence.sites():\\n            >>>     for mutation in site.mutations:\\n            >>>         yield mutation\\n\\n        :return: An iterator over all mutations in this tree sequence.\\n        :rtype: iter(:class:`Mutation`)\\n        \"\"\"\\n        for site in self.sites():\\n            yield from site.mutations\\n'), Document(id='6c14fad9-02e5-4152-b2cb-70ad1de7b015', metadata={'title': 'num_mutations'}, page_content='    @property\\n    def num_mutations(self):\\n        \"\"\"\\n        Returns the number of :ref:`mutations <sec_mutation_table_definition>`\\n        in this tree sequence.\\n\\n        :return: The number of mutations in this tree sequence.\\n        :rtype: int\\n        \"\"\"\\n        return self._ll_tree_sequence.get_num_mutations()\\n'), Document(metadata={'title': 'num_assignments_in_group'}, page_content='def num_assignments_in_group(g):\\n    \"\"\"\\n    Given this group of identical trees, how many unique ways\\n    are there to divide up a set of n labels?\\n    \"\"\"\\n    n = sum(t.num_leaves for t in g)\\n    total = 1\\n    for t in g:\\n        k = t.num_leaves\\n        # Choose k - 1 from n - 1 because the minimum label must be\\n        # assigned to the first tree for a canonical labelling.\\n        total *= Combination.comb(n - 1, k - 1)\\n        n -= k\\n    return total\\n\\n'), Document(metadata={'title': 'delete_sites'}, page_content='    def delete_sites(self, site_ids, record_provenance=True):\\n        \"\"\"\\n        Remove the specified sites entirely from the sites and mutations tables in this\\n        collection. This is identical to :meth:`TreeSequence.delete_sites` but acts\\n        *in place* to alter the data in this :class:`TableCollection`.\\n\\n        :param list[int] site_ids: A list of site IDs specifying the sites to remove.\\n        :param bool record_provenance: If ``True``, add details of this operation\\n            to the provenance table in this TableCollection. (Default: ``True``).\\n        \"\"\"\\n        keep_sites = np.ones(len(self.sites), dtype=bool)\\n        site_ids = util.safe_np_int_cast(site_ids, np.int32)\\n        if np.any(site_ids < 0) or np.any(site_ids >= len(self.sites)):\\n            raise ValueError(\"Site ID out of bounds\")\\n        keep_sites[site_ids] = 0\\n        new_as, new_as_offset = keep_with_offset(\\n            keep_sites, self.sites.ancestral_state, self.sites.ancestral_state_offset\\n        )\\n        new_md, new_md_offset = keep_with_offset(\\n            keep_sites, self.sites.metadata, self.sites.metadata_offset\\n        )\\n        self.sites.set_columns(\\n            position=self.sites.position[keep_sites],\\n            ancestral_state=new_as,\\n            ancestral_state_offset=new_as_offset,\\n            metadata=new_md,\\n            metadata_offset=new_md_offset,\\n        )\\n        # We also need to adjust the mutations table, as it references into sites\\n        keep_mutations = keep_sites[self.mutations.site]\\n        new_ds, new_ds_offset = keep_with_offset(\\n            keep_mutations,\\n            self.mutations.derived_state,\\n            self.mutations.derived_state_offset,\\n        )\\n        new_md, new_md_offset = keep_with_offset(\\n            keep_mutations, self.mutations.metadata, self.mutations.metadata_offset\\n        )\\n        # Site numbers will have changed\\n        site_map = np.cumsum(keep_sites, dtype=self.mutations.site.dtype) - 1\\n        # Mutation numbers will change, so the parent references need altering\\n        mutation_map = np.cumsum(keep_mutations, dtype=self.mutations.parent.dtype) - 1\\n        # Map parent == -1 to -1, and check this has worked (assumes tskit.NULL == -1)\\n        mutation_map = np.append(mutation_map, -1).astype(self.mutations.parent.dtype)\\n        assert mutation_map[tskit.NULL] == tskit.NULL\\n        self.mutations.set_columns(\\n            site=site_map[self.mutations.site[keep_mutations]],\\n            node=self.mutations.node[keep_mutations],\\n            time=self.mutations.time[keep_mutations],\\n            derived_state=new_ds,\\n            derived_state_offset=new_ds_offset,\\n            parent=mutation_map[self.mutations.parent[keep_mutations]],\\n            metadata=new_md,\\n            metadata_offset=new_md_offset,\\n        )\\n        if record_provenance:\\n            # TODO replace with a version of https://github.com/tskit-dev/tskit/pull/243\\n            parameters = {\"command\": \"delete_sites\", \"TODO\": \"add parameters\"}\\n            self.provenances.add_row(\\n                record=json.dumps(provenance.get_provenance_dict(parameters))\\n            )\\n'), Document(metadata={'title': None}, page_content='class LdCalculator:\\n    \"\"\"\\n    Class for calculating `linkage disequilibrium\\n    <https://en.wikipedia.org/wiki/Linkage_disequilibrium>`_ coefficients\\n    between pairs of sites in a :class:`TreeSequence`.\\n\\n    .. note:: This interface is deprecated and a replacement is planned.\\n        Please see https://github.com/tskit-dev/tskit/issues/1900 for\\n        more information. Note also that the current implementation is\\n        quite limited (see warning below).\\n\\n    .. warning:: This class does not currently support sites that have more than one\\n        mutation. Using it on such a tree sequence will raise a LibraryError with\\n        an \"Only infinite sites mutations supported\" message.\\n\\n        Silent mutations are also not supported and will result in a LibraryError.\\n\\n    :param TreeSequence tree_sequence: The tree sequence of interest.\\n    \"\"\"\\n'), Document(metadata={'title': 'Do you really need mutations?'}, page_content='<p>In tree sequences, the genetic genealogy exists independently of the mutations that\\ngenerate genetic variation, and often we are primarily interested in genetic variation\\nbecause of what it can tell us about those genealogies. This tutorial aims to illustrate\\nwhen we can leave mutations and genetic variation aside and study the genealogies directly.</p><p>In simulations we know the true genealogies, and so it can be very helpful to work\\nwith these directly.\\nIn real data, we might infer the trees and then work with the resulting genealogies.\\n(Of course, mutations add additional noise, and would be necessary\\nto produce data directly comparable to sequencing data.)\\nIf you\\'re wondering whether you need to add mutations at all,\\nit\\'s worth considering the following points:</p><ol>\\n<li>Neutral mutations and sites can always be added to a genealogy later</li>\\n<li>Simulating sites and mutations increases memory requirements and tree\\nsequence file size somewhat, as well as adding to CPU time (although usually this is\\ninconsequential)</li>\\n<li>Quantities of interest can often be inferred equally well (or better!) on tree sequences\\nthat have no sites or mutations.</li>\\n</ol><p>To illustrate the first two points, we can use the <a href=\"https://tskit.dev/msprime\">msprime</a>\\n{func}<code>~msprime.sim_mutations</code> function to add neutral sites and mutations onto an\\nsimulated mutationless tree sequence of 20 diploid individuals:</p><pre><code class=\"language-{code-cell}\">import msprime\\nL = 1_000_000  # simulate 1 megabase length (could increase for a larger example)\\nrho = mu = 1e-8  # Human-like recombination and mutation parameters\\nn_subpops = 2\\nsubpop_size = 1e4\\nmigration_rate = 1e-4\\n# Create a mutationless diploid tree sequence of n_subpops demes\\nts_no_mut = msprime.sim_ancestry(\\n    samples={f\"pop_{i}\": 10 for i in range(n_subpops)},  # 10 samples from each subpop\\n    demography=msprime.Demography.island_model([subpop_size] * n_subpops, migration_rate),\\n    ploidy=2,\\n    recombination_rate=rho,\\n    sequence_length=L,\\n    random_seed=123,\\n)\\n\\n# Optionally, add neutral mutations later, after simulating. This takes some CPU time\\n# (although it is usually fast compared to simulating the original tree sequence)\\nts_mutated = msprime.sim_mutations(ts_no_mut, rate=mu, random_seed=456)\\nprint(\\n    \"Adding mutations has increased the tree sequence file size by \"\\n    f\"{ts_mutated.nbytes / ts_no_mut.nbytes * 100:.0f}%\",\\n)\\n</code>'), Document(id='ce712325-e983-4191-9d52-d0ac5efa93ed', metadata={'title': 'Site and mutation tables'}, page_content='<p>There are four mutations in the depiction above,\\nmarked by red crosses: one above node <code>4</code> on the first tree which records an A to G\\ntransition at position 15, another above node <code>1</code> in the second tree which records a G\\nto A transition at position 42, and the final two above nodes <code>0</code> and <code>3</code> recording\\ntransitions, both at position 60, on the second tree. The positions are recorded in the\\n{class}<code>SiteTable</code> (details {ref}<code>here&lt;tskit:sec_site_table_definition&gt;</code>):</p><pre><code class=\"language-{code-cell}\">ts.tables.sites\\n</code>'), Document(id='e4573bd8-2a28-4c08-8fec-e8cd928fa50d', metadata={'title': 'Plotting mutations'}, page_content='<p>Note that, unusually, the rightmost site on the axis has more than one stacked chevron,\\nindicating that multiple mutations in the tree occur at the same site. These could be\\nmutations to different allelic states, or recurrent/back mutations. In this case the\\nmutations, 14 and 15 (above nodes 1 and 6) are recurrent mutations from T to G.</p><pre><code class=\"language-{code-cell}\">:\"tags\": [\"hide-input\"]\\nts_mutated = tskit.load(\"data/viz_ts_small_mutated.trees\")\\nsite_descr = str(next(ts_mutated.at_index(2).sites()))\\nprint(site_descr.replace(\"[\", \"[\\\\n  \").replace(\"),\", \"),\\\\n \").replace(\"],\", \"],\\\\n\"))\\n</code>'), Document(metadata={'title': 'SVG examples'}, page_content='<h4>A standard ts plot</h4><p>Note that this tree sequence also illustrates a few features which are not normally\\nproduced e.g. by <code>msprime</code> simulations, in particular a \"empty\" site (with no\\nassociated mutations) at position 50, and some mutations that occur above root nodes in\\nthe trees. Graphically, root mutations necessitate a line above the root node on which to\\nplace them, so each tree in this SVG has a nominal \"root branch\" at the top. Normally,\\nroot branches are not drawn, unless the <code>force_root_branch</code> parameter is specified.</p><pre><code class=\"language-{code-cell}\">:\"tags\": [\"hide-input\"]\\n# Make a tree sequence with multiple mutations including some above the root\\nimport io\\nimport tskit\\n\\ndef make_unusual_ts():\\n    nodes = io.StringIO(\\n        \"\"\"\\\\\\n    id      is_sample   population      individual      time    metadata\\n    0       1       0       -1      0\\n    1       1       0       -1      0\\n    2       1       0       -1      0\\n    3       1       0       -1      0\\n    4       0       0       -1      0.1145014598813\\n    5       0       0       -1      1.11067965364865\\n    6       0       0       -1      1.75005250750382\\n    7       0       0       -1      5.31067154311640\\n    8       0       0       -1      6.57331354884652\\n    9       0       0       -1      9.08308317451295\\n    \"\"\"\\n    )\\n    edges = io.StringIO(\\n        \"\"\"\\\\\\n    id      left   right   parent  child\\n    0       0      100     4       0\\n    1       0      100     4       1\\n    2       0      100     5       2\\n    3       0      100     5       3\\n    4       80     85      6       4\\n    5       80     85      6       5\\n    6       6      80      7       4\\n    7       85     91      7       4\\n    8       6      80      7       5\\n    9       85     91      7       5\\n    10      91     100     8       4\\n    11      91     100     8       5\\n    12      0      6       9       4\\n    13      0      6       9       5\\n    \"\"\"\\n    )\\n    sites = io.StringIO(\\n        \"\"\"\\\\\\n    position    ancestral_state\\n    4           A\\n    6           0\\n    30          Empty\\n    50          XXX\\n    91          T\\n    \"\"\"\\n    )\\n    muts = io.StringIO(\\n        \"\"\"\\\\\\n    site   node    derived_state    parent    time\\n    0      9       T                -1        15\\n    0      9       G                0         9.1\\n    0      5       1                1         9\\n    1      4       C                -1        1.6\\n    1      4       G                3         1.5\\n    2      7       G                -1        10\\n    2      3       C                5         1\\n    4      3       G                -1        1\\n    \"\"\"\\n    )\\n    return tskit.load_text(nodes, edges, sites=sites, mutations=muts, strict=False)\\n\\n\\nts = make_unusual_ts()\\nts.draw_svg()\\n</code>'), Document(metadata={'title': 'Other software'}, page_content='<p>:::{todo}\\nShow how ARGweaver output can be converted to tskit form.\\n:::</p><p>:::{todo}\\nShow how KwARG output can be converted to tskit form.\\n:::</p><p>:::{todo}\\nImplement conversion between the <em>msprime</em> 2 RE node version and the more conventional 1 RE node version. See https://github.com/tskit-dev/msprime/issues/1942 for extensive discussion on the advantages / disadvantages of using 2 nodes vs 1 node-with-metadata.\\n:::</p>')]\n",
      "Tools Error:  (status code: 404)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'message'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m final_context = rerank_documents(query, reranker, context, \u001b[32m3\u001b[39m)\n\u001b[32m      5\u001b[39m res = generatorTool(query, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(cont.page_content.strip() \u001b[38;5;28;01mfor\u001b[39;00m cont \u001b[38;5;129;01min\u001b[39;00m final_context))\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m code_gen = response_parser(\u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessage\u001b[49m.content)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(code_gen)\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'message'"
     ]
    }
   ],
   "source": [
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\") \n",
    "query=\"how many sites have 1 mutations\"\n",
    "context = ensemble_retriever.invoke(query)\n",
    "final_context = rerank_documents(query, reranker, context, 3)\n",
    "res = generatorTool(query, \"\\n\".join(cont.page_content.strip() for cont in final_context))\n",
    "code_gen = response_parser(res.message.content)\n",
    "print(code_gen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section <h1>Python API<a class=\"headerlink\" href=\"#python-api\" title=\"Link to this heading\">#</a></h1>\n",
      "subheader Trees and tree sequences#\n",
      "subheader TreeSequenceAPI#\n",
      "subheader General properties#\n",
      "subheader Efficient table column access#\n",
      "subheader Loading and saving#\n",
      "subheader Obtaining trees#\n",
      "subheader Obtaining other objects#\n",
      "subheader Tree topology#\n",
      "subheader Genetic variation#\n",
      "subheader Demography#\n",
      "subheader Other#\n",
      "subheader Tree sequence modification#\n",
      "subheader Identity by descent#\n",
      "subheader Tables#\n",
      "subheader Statistics#\n",
      "subheader Topological analysis#\n",
      "subheader Display#\n",
      "subheader Export#\n",
      "subheader TreeAPI#\n",
      "subheader General properties#\n",
      "subheader Creating new trees#\n",
      "subheader Node measures#\n",
      "subheader Simple measures#\n",
      "subheader Array access#\n",
      "subheader Tree traversal#\n",
      "subheader Topological analysis#\n",
      "subheader Comparing trees#\n",
      "subheader Balance/imbalance indices#\n",
      "subheader Sites and mutations#\n",
      "subheader Moving to other trees#\n",
      "subheader Display#\n",
      "subheader Export#\n",
      "subheader Tables and Table Collections#\n",
      "subheader TableCollectionAPI#\n",
      "subheader General properties#\n",
      "subheader Transformation#\n",
      "subheader Modification#\n",
      "subheader Creating a valid tree sequence#\n",
      "subheader Miscellaneous methods#\n",
      "subheader Export#\n",
      "subheader Table APIs#\n",
      "subheader Accessing table data#\n",
      "subheader Text columns#\n",
      "subheader Binary columns#\n",
      "subheader Table functions#\n",
      "subheader Metadata API#\n",
      "subheader Provenance#\n",
      "subheader Utility functions#\n",
      "subheader Reference documentation#\n",
      "subheader Constants#\n",
      "subheader Exceptions#\n",
      "subheader Top-level functions#\n",
      "subheader Tree and tree sequence classes#\n",
      "subheader TheTreeclass#\n",
      "subheader TheTreeSequenceclass#\n",
      "subheader Simple container classes#\n",
      "subheader TheIndividualclass#\n",
      "subheader TheNodeclass#\n",
      "subheader TheEdgeclass#\n",
      "subheader TheSiteclass#\n",
      "subheader TheMutationclass#\n",
      "subheader TheVariantclass#\n",
      "subheader TheMigrationclass#\n",
      "subheader ThePopulationclass#\n",
      "subheader TheProvenanceclass#\n",
      "subheader TheIntervalclass#\n",
      "subheader TheRankclass#\n",
      "subheader TableCollection and Table classes#\n",
      "subheader TheTableCollectionclass#\n",
      "subheader IndividualTableclasses#\n",
      "subheader Associated row class#\n",
      "subheader NodeTableclasses#\n",
      "subheader Associated row class#\n",
      "subheader EdgeTableclasses#\n",
      "subheader Associated row class#\n",
      "subheader MigrationTableclasses#\n",
      "subheader Associated row class#\n",
      "subheader SiteTableclasses#\n",
      "subheader Associated row class#\n",
      "subheader MutationTableclasses#\n",
      "subheader Associated row class#\n",
      "subheader PopulationTableclasses#\n",
      "subheader Associated row class#\n",
      "subheader ProvenanceTableclasses#\n",
      "subheader Associated row class#\n",
      "subheader Identity classes#\n",
      "subheader TheIdentitySegmentsclass#\n",
      "subheader TheIdentitySegmentListclass#\n",
      "subheader TheIdentitySegmentclass#\n",
      "subheader Miscellaneous classes#\n",
      "subheader TheReferenceSequenceclass#\n",
      "subheader TheMetadataSchemaclass#\n",
      "subheader TheTableMetadataSchemasclass#\n",
      "subheader TheTopologyCounterclass#\n",
      "subheader TheLdCalculatorclass#\n",
      "subheader TheTableCollectionIndexesclass#\n",
      "subheader TheSVGStringclass#\n",
      "subheader ThePCAResultclass#\n"
     ]
    }
   ],
   "source": [
    "import marko\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from langchain_core.documents import Document\n",
    "import pickle\n",
    "\n",
    "\n",
    "input_url = \"https://tskit.dev/tskit/docs/stable/python-api.html\"\n",
    "\n",
    "response = requests.get(input_url)\n",
    "html = marko.convert(response.text)\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "# sections = soup.find_all([\"h1\", 'h2','h3'])  # Split by headings\n",
    "article = soup.find_all('article')\n",
    "documents = []\n",
    "\n",
    "if article:\n",
    "    for section in article[0].find_all('section', recursive=False):  # Top-level sections\n",
    "        section_id = section.get('id')\n",
    "        header = section.find('h1') or section.find('h2')\n",
    "        paragraph = section.find('p')\n",
    "        content = \"\"\n",
    "        if header:\n",
    "            content += header.get_text(strip=True) + \" \"\n",
    "        if paragraph:\n",
    "            content += paragraph.get_text(strip=True)\n",
    "        print(\"Section\", header)\n",
    "        # file.write(f\"section: {header}\\n\")\n",
    "\n",
    "        if content:\n",
    "            document = Document(\n",
    "                 page_content=content,\n",
    "                 metadata={\"title\": header, 'type':'text'}\n",
    "                 )\n",
    "            documents.append(document)\n",
    "\n",
    "        for subsection in section.find_all('section', recursive=True):\n",
    "\n",
    "            subheader = subsection.find('h2') or subsection.find('h3') or subsection.find('h4') or subsection.find('h5')\n",
    "\n",
    "            if subheader:\n",
    "                    title = subheader.get_text(strip=True)\n",
    "                    subsection_id = subsection.get('id')\n",
    "                    subparagraph = subsection.find('p')\n",
    "                    print(\"subheader\", title)\n",
    "                    sub_content = \"\"\n",
    "                    if subparagraph:\n",
    "                        sub_content += subparagraph.get_text(strip=False) + \" \"\n",
    "                        document = Document(\n",
    "                            page_content=sub_content,\n",
    "                            metadata={\"title\": title, 'type':'text'}\n",
    "                            )\n",
    "                        documents.append(document)\n",
    "                        \n",
    "            if subsection.find_all('section'):\n",
    "                continue\n",
    "\n",
    "            tables = subsection.find_all('table')\n",
    "            dls = subsection.find_all('dl')\n",
    "            sub_content = \"\"\n",
    "            if dls and len(tables)==0:\n",
    "                for dl in dls:\n",
    "                    dl_title = dl.find('dt').get_text()\n",
    "                    dl_text = dl.get_text(strip=False)\n",
    "                    document = Document(\n",
    "                        page_content=dl_text,\n",
    "                        metadata={\"title\": dl_title, 'type':'code'}\n",
    "                        )\n",
    "                    documents.append(document)\n",
    "            if len(tables)>0:\n",
    "                for table in tables:\n",
    "                    rows = table.find('tbody').find_all('tr')\n",
    "                    for row in rows:\n",
    "                        table_paragraph = \"\"\n",
    "                        cells = row.find_all('td')\n",
    "                        if len(cells) == 2:\n",
    "                            property_name = cells[0].get_text(strip=True)\n",
    "                            description = cells[1].get_text(strip=True)\n",
    "                            table_paragraph += f\"{property_name}: {description}. \"\n",
    "\n",
    "                            document = Document(\n",
    "                                page_content=table_paragraph,\n",
    "                                metadata={\"title\": property_name, 'type':'code'}\n",
    "                                )\n",
    "                            documents.append(document)\n",
    "\n",
    "with open(\"/storage2/pratik/git/code-chunker/documents.pkl\", 'rb') as file:\n",
    "    all_documents = pickle.load(file)\n",
    "all_documents.extend(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "bm25_retriever = BM25Retriever.from_documents(documents=all_documents, k=10, search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hybrid retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "vector_store = FAISS.load_local(folder_path=\"/storage2/pratik/git/code-chunker/faiss-vector\", embeddings=embeddings, index_name=\"faiss_index\", allow_dangerous_deserialization=True)\n",
    "\n",
    "\n",
    "faiss_retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.5, \"k\": 10}\n",
    ")\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever],\n",
    "    weights=[0.5, 0.5]  # Adjust based on your use case\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/anaconda3/envs/treesequence/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/storage2/pratik/git/lorax/lorax/langgraph_tskit.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat, generate\n",
    "from pydantic import BaseModel, Field\n",
    "from lorax.faiss_vector import rerank_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "class code(BaseModel):\n",
    "    \"\"\"\n",
    "    Schema for code solutions for questions about tskit. \n",
    "    \"\"\"\n",
    "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
    "    imports: str = Field(description=\"Code block import statements\")\n",
    "    code: str = Field(description=\"Code block should contain function that can be called. It should have input file_path to tree_sequence. It should not include import statements\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"how many sites have 1 mutations\"\n",
    "\n",
    "context = ensemble_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_context = rerank_documents(query, context, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e4573bd8-2a28-4c08-8fec-e8cd928fa50d', metadata={'title': 'Plotting mutations'}, page_content='<p>Note that, unusually, the rightmost site on the axis has more than one stacked chevron,\\nindicating that multiple mutations in the tree occur at the same site. These could be\\nmutations to different allelic states, or recurrent/back mutations. In this case the\\nmutations, 14 and 15 (above nodes 1 and 6) are recurrent mutations from T to G.</p><pre><code class=\"language-{code-cell}\">:\"tags\": [\"hide-input\"]\\nts_mutated = tskit.load(\"data/viz_ts_small_mutated.trees\")\\nsite_descr = str(next(ts_mutated.at_index(2).sites()))\\nprint(site_descr.replace(\"[\", \"[\\\\n  \").replace(\"),\", \"),\\\\n \").replace(\"],\", \"],\\\\n\"))\\n</code>'),\n",
       " Document(metadata={'title': None}, page_content='class LdCalculator:\\n    \"\"\"\\n    Class for calculating `linkage disequilibrium\\n    <https://en.wikipedia.org/wiki/Linkage_disequilibrium>`_ coefficients\\n    between pairs of sites in a :class:`TreeSequence`.\\n\\n    .. note:: This interface is deprecated and a replacement is planned.\\n        Please see https://github.com/tskit-dev/tskit/issues/1900 for\\n        more information. Note also that the current implementation is\\n        quite limited (see warning below).\\n\\n    .. warning:: This class does not currently support sites that have more than one\\n        mutation. Using it on such a tree sequence will raise a LibraryError with\\n        an \"Only infinite sites mutations supported\" message.\\n\\n        Silent mutations are also not supported and will result in a LibraryError.\\n\\n    :param TreeSequence tree_sequence: The tree sequence of interest.\\n    \"\"\"\\n'),\n",
       " Document(metadata={'title': 'num_mutations'}, page_content='    @property\\n    def num_mutations(self):\\n        \"\"\"\\n        Returns the total number of mutations across all sites on this tree.\\n\\n        :return: The total number of mutations over all sites on this tree.\\n        :rtype: int\\n        \"\"\"\\n        return sum(len(site.mutations) for site in self.sites())\\n')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = generatorTool(query, \"\\n\".join(cont.page_content.strip() for cont in final_context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def response_parser(text):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'prefix': '',\n",
    "        'imports': '',\n",
    "        'code': ''\n",
    "    }\n",
    "    sections = re.split(r'\\*\\*([^\\*]+)\\*\\*', text)\n",
    "\n",
    "    for i in range(1, len(sections), 2):\n",
    "        header = sections[i].strip()\n",
    "        content = sections[i+1].strip()\n",
    "        if header == 'Prefix':\n",
    "            result['prefix'] = content\n",
    "        \n",
    "        elif header == 'Imports':\n",
    "            code_match = re.search(r'```python(.*?)```', content, re.DOTALL)\n",
    "            if code_match:\n",
    "                result['imports'] = code_match.group(1).strip()\n",
    "\n",
    "        elif header == 'Code':\n",
    "            code_match = re.search(r'```python(.*?)```', content, re.DOTALL)\n",
    "            if code_match:\n",
    "                result['code'] = code_match.group(1).strip()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_gen = response_parser(res.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def count_sites_with_one_mutation(tree_file):\n",
      "    ts_mutated = tskit.load(tree_file)\n",
      "    sites_with_one_mutation = sum(1 for site in ts_mutated.sites() if len(site.mutations) == 1)\n",
      "    return f\"There are {sites_with_one_mutation} sites with exactly one mutation.\"\n"
     ]
    }
   ],
   "source": [
    "print(code_gen['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tskit\n",
    "def count_sites_with_one_mutation(tree_file):\n",
    "    ts_mutated = tskit.load(tree_file)\n",
    "    sites_with_one_mutation = sum(1 for site in ts_mutated.sites() if len(site.mutations) == 1)\n",
    "    return f\"There are {sites_with_one_mutation} sites with exactly one mutation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 503556 sites with exactly one mutation.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_sites_with_one_mutation('data/sample.trees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "# model = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L6-v2\")\n",
    "# scores = model.predict([[\"My first\", \"sentence pair\"], [\"Second text\", \"pair\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_documents(query, context, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lorax.tools import generatorTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = generatorTool(\"how many intervals does all the trees cover in the given tree-sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.loads(res.response)['code'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(res.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tree_sequence = tskit.load(\"./data/sample.trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_sequence.num_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
    "\n",
    "text = \"def hello_world():\"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "generated_ids = model.generate(input_ids, max_length=128)\n",
    "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
