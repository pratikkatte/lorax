{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from Chunker import CodeChunker, CodeParser\n",
    "from tree_sitter_languages import get_parser\n",
    "import marko\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.documents import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_documents_from_url(input_url: str):\n",
    "    response = requests.get(input_url)\n",
    "    html = marko.convert(response.text)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    article = soup.find_all('article')\n",
    "    documents = []\n",
    "\n",
    "    if article:\n",
    "        for section in article[0].find_all('section', recursive=False):  # Top-level sections\n",
    "            section_id = section.get('id')\n",
    "            header = section.find('h1') or section.find('h2')\n",
    "            paragraph = section.find('p')\n",
    "            content = \"\"\n",
    "            if header:\n",
    "                content += header.get_text(strip=True) + \" \"\n",
    "            if paragraph:\n",
    "                content += paragraph.get_text(strip=True)\n",
    "\n",
    "            if content:\n",
    "                documents.append(Document(\n",
    "                    page_content=content,\n",
    "                    metadata={\"title\": header.get_text(strip=True) if header else \"\", 'type': 'text'}\n",
    "                ))\n",
    "\n",
    "            for subsection in section.find_all('section', recursive=True):\n",
    "                subheader = (subsection.find('h2') or subsection.find('h3') or\n",
    "                             subsection.find('h4') or subsection.find('h5'))\n",
    "                if subheader:\n",
    "                    title = subheader.get_text(strip=True)\n",
    "                    subparagraph = subsection.find('p')\n",
    "                    sub_content = subparagraph.get_text(strip=False) if subparagraph else \"\"\n",
    "                    if sub_content:\n",
    "                        documents.append(Document(\n",
    "                            page_content=sub_content,\n",
    "                            metadata={\"title\": title, 'type': 'text'}\n",
    "                        ))\n",
    "\n",
    "                tables = subsection.find_all('table')\n",
    "                dls = subsection.find_all('dl')\n",
    "\n",
    "                if dls and not tables:\n",
    "                    for dl in dls:\n",
    "                        dt = dl.find('dt')\n",
    "                        if dt:\n",
    "                            dl_title = dt.get_text(strip=True)\n",
    "                            dl_text = dl.get_text(strip=False)\n",
    "                            documents.append(Document(\n",
    "                                page_content=dl_text,\n",
    "                                metadata={\"title\": dl_title, 'type': 'code'}\n",
    "                            ))\n",
    "\n",
    "                if tables:\n",
    "                    for table in tables:\n",
    "                        rows = table.find('tbody').find_all('tr')\n",
    "                        for row in rows:\n",
    "                            cells = row.find_all('td')\n",
    "                            if len(cells) == 2:\n",
    "                                property_name = cells[0].get_text(strip=True)\n",
    "                                description = cells[1].get_text(strip=True)\n",
    "                                table_paragraph = f\"{property_name}: {description}. \"\n",
    "                                documents.append(Document(\n",
    "                                    page_content=table_paragraph,\n",
    "                                    metadata={\"title\": property_name, 'type': 'code'}\n",
    "                                ))\n",
    "\n",
    "    return documents\n",
    "\n",
    "def create_document(input_url, log=False, ignore_first_section=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "\n",
    "    response = requests.get(input_url)\n",
    "    html = marko.convert(response.text)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    sections = soup.find_all([\"h1\", 'h2','h3'])  # Split by headings\n",
    "    if log:\n",
    "        pass\n",
    "        # print(\"sections\")\n",
    "        # print(sections)\n",
    "\n",
    "    for section in sections[1:]:\n",
    "        section_title = section.get_text()\n",
    "        if log:\n",
    "            print(section_title)\n",
    "        text = ''\n",
    "        for i, elem in enumerate(section.find_next_siblings()):\n",
    "            if elem.name in [\"h3\"]:\n",
    "                break\n",
    "            text = text + str(elem)\n",
    "    \n",
    "        chunks = text.split(\"</pre>\")\n",
    "        for chunk in chunks:\n",
    "            document = Document(\n",
    "            page_content=chunk,\n",
    "            # metadata={\"title\": section_title, \"contextual_content\": text+chunk}, ## add contextual summarizer later. \n",
    "            metadata={\"title\": section_title}\n",
    "            )            \n",
    "            documents.append(document)\n",
    "            \n",
    "    return documents\n",
    "\n",
    "def extract_function_name(code):\n",
    "    parser = get_parser(\"python\")\n",
    "    tree = parser.parse(bytes(code, \"utf-8\"))\n",
    "    \n",
    "    def traverse(node):\n",
    "        if node.type == \"function_definition\":\n",
    "            for child in node.children:\n",
    "                if child.type == \"identifier\":\n",
    "                    return code[child.start_byte:child.end_byte]\n",
    "        for child in node.children:\n",
    "            result = traverse(child)\n",
    "            if result:\n",
    "                return result\n",
    "        return None\n",
    "    \n",
    "    return traverse(tree.root_node)\n",
    "\n",
    "def codeChunking(input_urls):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    chunker = CodeChunker(file_extension='py', encoding_name='gpt-4')\n",
    "    all_chunk = []\n",
    "    for url in input_urls:\n",
    "        response = requests.get(url)\n",
    "        data = response.text\n",
    "        chunks = chunker.chunk(data, token_limit=25)\n",
    "        for cidx, chunk in chunks.items():\n",
    "            all_chunk.append(chunk)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for chunk in all_chunk:\n",
    "        title = extract_function_name(chunk)\n",
    "        document = Document(\n",
    "            page_content=chunk,\n",
    "            # metadata={\"title\": section_title, \"contextual_content\": text+chunk}, ## add contextual summarizer later. \n",
    "            metadata={\"title\": title, 'type':'code'}\n",
    "            )\n",
    "        documents.append(document)    \n",
    "    return documents\n",
    "\n",
    "input_url = \"https://tskit.dev/tskit/docs/stable/python-api.html\"\n",
    "\n",
    "python_code_urls = [\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/combinatorics.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/drawing.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/exceptions.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/formats.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/genotypes.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/intervals.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/metadata.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/provenance.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/stats.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/tables.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/text_formats.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/trees.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/text_formats.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/trees.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/util.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/vcf.py\"\n",
    "]\n",
    "\n",
    "\n",
    "doc_urls = [\n",
    "\"https://tskit.dev/tutorials/_sources/what_is.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/terminology_and_concepts.md\"\n",
    "\"https://tskit.dev/tutorials/_sources/getting_started.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/analysing_tree_sequences.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/analysing_trees.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/incremental_algorithms.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/counting_topologies.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/parallelization.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/tables_and_editing.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/viz.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/metadata.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/args.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/simulation_overview.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/no_mutations.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/demography.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/bottlenecks.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/introgression.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/completing_forward_sims.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/forward_sims.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/more_forward_sims.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/popgen.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/phylogen.md\"\n",
    "]\n",
    "ref_documents = extract_documents_from_url(input_url)\n",
    "python_documents = codeChunking(python_code_urls)\n",
    "\n",
    "tutoial_docs = []\n",
    "for url in doc_urls:\n",
    "    documents = create_document(url)\n",
    "    tutoial_docs.extend(documents)\n",
    "\n",
    "all_documents = []\n",
    "all_documents.extend(ref_documents)\n",
    "all_documents.extend(python_documents)\n",
    "all_documents.extend(tutoial_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save documents\n",
    "import pickle\n",
    "\n",
    "with open('documents.pkl', 'wb') as f:\n",
    "    pickle.dump(all_documents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save FAISS Embeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=all_documents,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "vector_store.save_local(folder_path=\"faiss-vector\", index_name=\"faiss_index\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treesequence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
