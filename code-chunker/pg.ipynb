{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing HTML Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marko\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def extract_documents_from_url(input_url: str):\n",
    "    response = requests.get(input_url)\n",
    "    html = marko.convert(response.text)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    article = soup.find_all('article')\n",
    "    documents = []\n",
    "\n",
    "    if article:\n",
    "        for section in article[0].find_all('section', recursive=False):  # Top-level sections\n",
    "            section_id = section.get('id')\n",
    "            header = section.find('h1') or section.find('h2')\n",
    "            paragraph = section.find('p')\n",
    "            content = \"\"\n",
    "            if header:\n",
    "                content += header.get_text(strip=True) + \" \"\n",
    "            if paragraph:\n",
    "                content += paragraph.get_text(strip=True)\n",
    "\n",
    "            if content:\n",
    "                documents.append(Document(\n",
    "                    page_content=content,\n",
    "                    metadata={\"title\": header.get_text(strip=True) if header else \"\", 'type': 'text'}\n",
    "                ))\n",
    "\n",
    "            for subsection in section.find_all('section', recursive=True):\n",
    "                subheader = (subsection.find('h2') or subsection.find('h3') or\n",
    "                             subsection.find('h4') or subsection.find('h5'))\n",
    "                if subheader:\n",
    "                    title = subheader.get_text(strip=True)\n",
    "                    subparagraph = subsection.find('p')\n",
    "                    sub_content = subparagraph.get_text(strip=False) if subparagraph else \"\"\n",
    "                    if sub_content:\n",
    "                        documents.append(Document(\n",
    "                            page_content=sub_content,\n",
    "                            metadata={\"title\": title, 'type': 'text'}\n",
    "                        ))\n",
    "\n",
    "                tables = subsection.find_all('table')\n",
    "                dls = subsection.find_all('dl')\n",
    "\n",
    "                if dls and not tables:\n",
    "                    for dl in dls:\n",
    "                        dt = dl.find('dt')\n",
    "                        if dt:\n",
    "                            dl_title = dt.get_text(strip=True)\n",
    "                            dl_text = dl.get_text(strip=False)\n",
    "                            documents.append(Document(\n",
    "                                page_content=dl_text,\n",
    "                                metadata={\"title\": dl_title, 'type': 'code'}\n",
    "                            ))\n",
    "\n",
    "                if tables:\n",
    "                    for table in tables:\n",
    "                        rows = table.find('tbody').find_all('tr')\n",
    "                        for row in rows:\n",
    "                            cells = row.find_all('td')\n",
    "                            if len(cells) == 2:\n",
    "                                property_name = cells[0].get_text(strip=True)\n",
    "                                description = cells[1].get_text(strip=True)\n",
    "                                table_paragraph = f\"{property_name}: {description}. \"\n",
    "                                documents.append(Document(\n",
    "                                    page_content=table_paragraph,\n",
    "                                    metadata={\"title\": property_name, 'type': 'code'}\n",
    "                                ))\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "# input_url = \"https://tskit.dev/tskit/docs/stable/python-api.html\"\n",
    "\n",
    "# ref_documents = extract_documents_from_url(input_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code-Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/anaconda3/envs/code-chunker/lib/python3.11/site-packages/tree_sitter/__init__.py:36: FutureWarning: Language.build_library is deprecated. Use the new bindings instead.\n",
      "  warn(\"{} is deprecated. Use {} instead.\".format(old, new), FutureWarning)\n",
      "/home/pratik/anaconda3/envs/code-chunker/lib/python3.11/site-packages/tree_sitter/__init__.py:36: FutureWarning: Language(path, name) is deprecated. Use Language(ptr, name) instead.\n",
      "  warn(\"{} is deprecated. Use {} instead.\".format(old, new), FutureWarning)\n",
      "2025-05-06 14:23:38,803 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:39,116 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:39,456 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:39,675 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:39,729 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:39,813 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:39,897 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:40,010 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:40,074 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:40,144 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:40,586 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:40,700 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:41,848 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:41,934 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:43,104 - INFO - Successfully built and loaded python parser\n",
      "2025-05-06 14:23:43,197 - INFO - Successfully built and loaded python parser\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from Chunker import CodeChunker, CodeParser\n",
    "from tree_sitter_languages import get_parser\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import marko\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def create_document(input_url, log=False, ignore_first_section=True):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "\n",
    "    response = requests.get(input_url)\n",
    "    html = marko.convert(response.text)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    sections = soup.find_all([\"h1\", 'h2','h3'])  # Split by headings\n",
    "    if log:\n",
    "        pass\n",
    "        # print(\"sections\")\n",
    "        # print(sections)\n",
    "\n",
    "    for section in sections[1:]:\n",
    "        section_title = section.get_text()\n",
    "        if log:\n",
    "            print(section_title)\n",
    "        text = ''\n",
    "        for i, elem in enumerate(section.find_next_siblings()):\n",
    "            if elem.name in [\"h3\"]:\n",
    "                break\n",
    "            text = text + str(elem)\n",
    "    \n",
    "        chunks = text.split(\"</pre>\")\n",
    "        for chunk in chunks:\n",
    "            document = Document(\n",
    "            page_content=chunk,\n",
    "            # metadata={\"title\": section_title, \"contextual_content\": text+chunk}, ## add contextual summarizer later. \n",
    "            metadata={\"title\": section_title}\n",
    "            )            \n",
    "            documents.append(document)\n",
    "            \n",
    "    return documents\n",
    "\n",
    "def extract_function_name(code):\n",
    "    parser = get_parser(\"python\")\n",
    "    tree = parser.parse(bytes(code, \"utf-8\"))\n",
    "    \n",
    "    def traverse(node):\n",
    "        if node.type == \"function_definition\":\n",
    "            for child in node.children:\n",
    "                if child.type == \"identifier\":\n",
    "                    return code[child.start_byte:child.end_byte]\n",
    "        for child in node.children:\n",
    "            result = traverse(child)\n",
    "            if result:\n",
    "                return result\n",
    "        return None\n",
    "    \n",
    "    return traverse(tree.root_node)\n",
    "\n",
    "def codeChunking(input_urls):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    chunker = CodeChunker(file_extension='py', encoding_name='gpt-4')\n",
    "    all_chunk = []\n",
    "    for url in input_urls:\n",
    "        response = requests.get(url)\n",
    "        data = response.text\n",
    "        chunks = chunker.chunk(data, token_limit=25)\n",
    "        for cidx, chunk in chunks.items():\n",
    "            all_chunk.append(chunk)\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for chunk in all_chunk:\n",
    "        title = extract_function_name(chunk)\n",
    "        document = Document(\n",
    "            page_content=chunk,\n",
    "            # metadata={\"title\": section_title, \"contextual_content\": text+chunk}, ## add contextual summarizer later. \n",
    "            metadata={\"title\": title, 'type':'code'}\n",
    "            )\n",
    "        documents.append(document)    \n",
    "    return documents\n",
    "\n",
    "input_url = \"https://tskit.dev/tskit/docs/stable/python-api.html\"\n",
    "\n",
    "python_code_urls = [\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/combinatorics.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/drawing.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/exceptions.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/formats.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/genotypes.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/intervals.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/metadata.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/provenance.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/stats.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/tables.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/text_formats.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/trees.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/text_formats.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/trees.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/util.py\",\n",
    "\"https://raw.githubusercontent.com/tskit-dev/tskit/refs/heads/main/python/tskit/vcf.py\"\n",
    "]\n",
    "\n",
    "\n",
    "doc_urls = [\n",
    "\"https://tskit.dev/tutorials/_sources/what_is.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/terminology_and_concepts.md\"\n",
    "\"https://tskit.dev/tutorials/_sources/getting_started.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/analysing_tree_sequences.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/analysing_trees.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/incremental_algorithms.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/counting_topologies.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/parallelization.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/tables_and_editing.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/viz.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/metadata.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/args.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/simulation_overview.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/no_mutations.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/demography.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/bottlenecks.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/introgression.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/completing_forward_sims.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/forward_sims.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/more_forward_sims.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/popgen.md\",\n",
    "\"https://tskit.dev/tutorials/_sources/phylogen.md\"\n",
    "]\n",
    "ref_documents = extract_documents_from_url(input_url)\n",
    "python_documents = codeChunking(python_code_urls)\n",
    "\n",
    "tutoial_docs = []\n",
    "for url in doc_urls:\n",
    "    documents = create_document(url)\n",
    "    tutoial_docs.extend(documents)\n",
    "\n",
    "all_documents = []\n",
    "all_documents.extend(ref_documents)\n",
    "all_documents.extend(python_documents)\n",
    "all_documents.extend(tutoial_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the indexing (faiss-vector folder) and documents into pkl file (documents.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Increase the limit\u001b[39;00m\n\u001b[32m      7\u001b[39m embeddings = OllamaEmbeddings(model=\u001b[33m\"\u001b[39m\u001b[33mnomic-embed-text\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m vector_store = \u001b[43mFAISS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_documents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m vector_store.save_local(folder_path=\u001b[33m\"\u001b[39m\u001b[33mfaiss-vector\u001b[39m\u001b[33m\"\u001b[39m, index_name=\u001b[33m\"\u001b[39m\u001b[33mfaiss_index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33msafe.pkl\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/langchain_core/vectorstores/base.py:848\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    846\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/langchain_community/vectorstores/faiss.py:1043\u001b[39m, in \u001b[36mFAISS.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mfrom_texts\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     **kwargs: Any,\n\u001b[32m   1024\u001b[39m ) -> FAISS:\n\u001b[32m   1025\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \n\u001b[32m   1027\u001b[39m \u001b[33;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m \u001b[33;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[32m   1042\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m     embeddings = \u001b[43membedding\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__from(\n\u001b[32m   1045\u001b[39m         texts,\n\u001b[32m   1046\u001b[39m         embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1050\u001b[39m         **kwargs,\n\u001b[32m   1051\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/langchain_ollama/embeddings.py:242\u001b[39m, in \u001b[36mOllamaEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    241\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Embed search docs.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     embedded_docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_default_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeep_alive\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embedded_docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/ollama/_client.py:357\u001b[39m, in \u001b[36mClient.embed\u001b[39m\u001b[34m(self, model, input, truncate, options, keep_alive)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34membed\u001b[39m(\n\u001b[32m    350\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    351\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    355\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    356\u001b[39m ) -> EmbedResponse:\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEmbedResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/embed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEmbedRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/ollama/_client.py:178\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/ollama/_client.py:118\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    117\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     r.raise_for_status()\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpx/_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/code-chunker/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import pickle\n",
    "import sys\n",
    "# Increase the limit\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents=all_documents,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "vector_store.save_local(folder_path=\"faiss-vector\", index_name=\"faiss_index\")\n",
    "\n",
    "\n",
    "with open('documents.pkl', 'wb') as f:\n",
    "    pickle.dump(all_documents, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "\n",
    "# Create hybrid retriever\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(documents=all_documents)\n",
    "faiss_retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever],\n",
    "    weights=[0.5, 0.5]  # Adjust based on your use case\n",
    ")\n",
    "query=\"how many sites are there\"\n",
    "\n",
    "ensemble_retriever.invoke(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extras --- trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marko\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "input_url = \"https://tskit.dev/tskit/docs/stable/python-api.html\"\n",
    "\n",
    "response = requests.get(input_url)\n",
    "html = marko.convert(response.text)\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "# sections = soup.find_all([\"h1\", 'h2','h3'])  # Split by headings\n",
    "article = soup.find_all('article')\n",
    "documents = []\n",
    "\n",
    "if article:\n",
    "    for section in article[0].find_all('section', recursive=False):  # Top-level sections\n",
    "        section_id = section.get('id')\n",
    "        header = section.find('h1') or section.find('h2')\n",
    "        paragraph = section.find('p')\n",
    "        content = \"\"\n",
    "        if header:\n",
    "            content += header.get_text(strip=True) + \" \"\n",
    "        if paragraph:\n",
    "            content += paragraph.get_text(strip=True)\n",
    "        print(\"Section\", header)\n",
    "        # file.write(f\"section: {header}\\n\")\n",
    "\n",
    "        if content:\n",
    "            document = Document(\n",
    "                 page_content=content,\n",
    "                 metadata={\"title\": header, 'type':'text'}\n",
    "                 )\n",
    "            documents.append(document)\n",
    "\n",
    "        for subsection in section.find_all('section', recursive=True):\n",
    "\n",
    "            subheader = subsection.find('h2') or subsection.find('h3') or subsection.find('h4') or subsection.find('h5')\n",
    "\n",
    "            if subheader:\n",
    "                    title = subheader.get_text(strip=True)\n",
    "                    subsection_id = subsection.get('id')\n",
    "                    subparagraph = subsection.find('p')\n",
    "                    print(\"subheader\", title)\n",
    "                    sub_content = \"\"\n",
    "                    if subparagraph:\n",
    "                        sub_content += subparagraph.get_text(strip=False) + \" \"\n",
    "                        document = Document(\n",
    "                            page_content=sub_content,\n",
    "                            metadata={\"title\": title, 'type':'text'}\n",
    "                            )\n",
    "                        documents.append(document)\n",
    "                        \n",
    "            if subsection.find_all('section'):\n",
    "                \n",
    "                continue\n",
    "\n",
    "            tables = subsection.find_all('table')\n",
    "            dls = subsection.find_all('dl')\n",
    "            sub_content = \"\"\n",
    "\n",
    "            # if subheader:\n",
    "            #     title = subheader.get_text(strip=True)\n",
    "                \n",
    "            #     if subparagraph:\n",
    "            #         sub_content += subparagraph.get_text(strip=True) + \" \"\n",
    "                    \n",
    "            #         document = Document(\n",
    "            #             page_content=sub_content,\n",
    "            #             metadata={\"title\": title, 'type':'text'}\n",
    "            #             )\n",
    "\n",
    "            #         documents.append(document)\n",
    "            \n",
    "            if \"Constants\" in subheader.get_text() :\n",
    "                print(\"tables\", tables)\n",
    "            if dls and len(tables)==0:\n",
    "                for dl in dls:\n",
    "                    dl_title = dl.find('dt').get_text()\n",
    "                    dl_text = dl.get_text(strip=False)\n",
    "                    document = Document(\n",
    "                        page_content=dl_text,\n",
    "                        metadata={\"title\": dl_title, 'type':'code'}\n",
    "                        )\n",
    "                    documents.append(document)\n",
    "            if len(tables)>0:\n",
    "                for table in tables:\n",
    "\n",
    "                    rows = table.find('tbody').find_all('tr')\n",
    "                    for row in rows:\n",
    "                        table_paragraph = \"\"\n",
    "                        cells = row.find_all('td')\n",
    "                        if len(cells) == 2:\n",
    "                            property_name = cells[0].get_text(strip=True)\n",
    "                            description = cells[1].get_text(strip=True)\n",
    "                            table_paragraph += f\"{property_name}: {description}. \"\n",
    "\n",
    "                            document = Document(\n",
    "                                page_content=table_paragraph,\n",
    "                                metadata={\"title\": property_name, 'type':'code'}\n",
    "                                )\n",
    "                            documents.append(document)\n",
    "                            # print(table_paragraph)\n",
    "                            # file.write(f\"\\ntable_paragraph: {table_paragraph}\")\n",
    "            # print(\"-\"*100)\n",
    "            # file.write(f\"\\n{'-'*100}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"how many sites are there\"\n",
    "results=vector_store.similarity_search_with_score(query=query, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.save_local(folder_path=\"faiss-vector\", index_name=\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(documents=all_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hybrid retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "\n",
    "faiss_retriever = vector_store.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever],\n",
    "    weights=[0.5, 0.5]  # Adjust based on your use case\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"how many sites are there\"\n",
    "\n",
    "ensemble_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in results:\n",
    "    print(res[0].page_content)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-chunker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
